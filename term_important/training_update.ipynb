{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b54b8d6",
   "metadata": {},
   "source": [
    "## DATA GENERATOR FILE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "746b191d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 341\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Dict, Any\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mUniTimeDatasetGeneratorWithUpdate\u001b[39;00m:\n\u001b[32m    344\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# # import json\n",
    "# # import random\n",
    "# # import os\n",
    "# # from datetime import datetime\n",
    "# # from typing import List, Dict, Any\n",
    "# # from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # class UniTimeDatasetGeneratorWithUpdate:\n",
    "# #     def __init__(self):\n",
    "# #         self.campus = \"woebegon\"\n",
    "# #         self.year = \"2010\"\n",
    "# #         self.term = \"Fal\"\n",
    "# #         self.date_format = \"yyyy/M/d\"\n",
    "# #         self.time_format = \"HHmm\"\n",
    "# #         self.created = datetime.now().strftime(\"%a %b %d %H:%M:%S CEST %Y\")\n",
    "# #         self.include_exams = \"none\"\n",
    "# #         self.managing_dept = \"0100\"\n",
    "        \n",
    "# #         # Possible data pools\n",
    "# #         self.subjects = [\"CS\", \"MATH\", \"PHYS\", \"CHEM\", \"ENGL\"]\n",
    "# #         self.course_numbers = [\"101\", \"201\", \"301\"]\n",
    "# #         self.titles = {\n",
    "# #             \"CS\": [\"Intro to Programming\", \"Data Structures\"],\n",
    "# #             \"MATH\": [\"Calculus I\", \"Linear Algebra\"],\n",
    "# #             \"PHYS\": [\"Physics I\", \"Physics II\"],\n",
    "# #         }\n",
    "# #         self.buildings = {\"Science Hall\": \"SCI\", \"Education Center\": \"EDU\", \"Engineering\": \"ENG\"}\n",
    "# #         self.room_numbers = [\"101\", \"205\", \"301\", \"B08\"]\n",
    "# #         self.day_patterns = [\"MWF\", \"TTh\"]\n",
    "# #         self.time_slots = [(\"0830\", \"0920\", 50), (\"0930\", \"1020\", 50), (\"1330\", \"1420\", 50)]\n",
    "# #         self.limits = [20, 25, 30, 40]\n",
    "# #         self.class_types = [\"Lec\", \"Lab\"]\n",
    "\n",
    "# #     def _calculate_min_per_week(self, days: str, duration: int) -> int:\n",
    "# #         # Simple approach\n",
    "# #         day_count = 0\n",
    "# #         if \"M\" in days: day_count += 1\n",
    "# #         if \"W\" in days: day_count += 1\n",
    "# #         if \"F\" in days: day_count += 1\n",
    "# #         if \"T\" in days and \"Th\" in days: day_count += 2\n",
    "# #         elif \"T\" in days: day_count += 1\n",
    "# #         return day_count * duration\n",
    "\n",
    "# #     def _time_pattern(self, days: str, duration: int) -> str:\n",
    "# #         # e.g. \"3 x 50\"\n",
    "# #         day_count = len(days)  # naive\n",
    "# #         return f\"{day_count} x {duration}\"\n",
    "\n",
    "# #     def _generate_base_details(self) -> Dict[str, Any]:\n",
    "# #         subject = random.choice(self.subjects)\n",
    "# #         courseNbr = random.choice(self.course_numbers)\n",
    "# #         title = random.choice(self.titles.get(subject, [\"Title\"]))\n",
    "# #         classType = random.choice(self.class_types)\n",
    "# #         (start, end, dur) = random.choice(self.time_slots)\n",
    "# #         days = random.choice(self.day_patterns)\n",
    "# #         buildingName = random.choice(list(self.buildings.keys()))\n",
    "# #         buildingCode = self.buildings[buildingName]\n",
    "# #         roomNbr = random.choice(self.room_numbers)\n",
    "# #         limit = random.choice(self.limits)\n",
    "# #         minPerWeek = self._calculate_min_per_week(days, dur)\n",
    "# #         timePattern = self._time_pattern(days, dur)\n",
    "# #         return {\n",
    "# #             \"subject\": subject,\n",
    "# #             \"courseNbr\": courseNbr,\n",
    "# #             \"title_desc\": title,\n",
    "# #             \"classType\": classType,\n",
    "# #             \"startTime\": start,\n",
    "# #             \"endTime\": end,\n",
    "# #             \"days\": days,\n",
    "# #             \"duration\": dur,\n",
    "# #             \"buildingName\": buildingName,\n",
    "# #             \"buildingCode\": buildingCode,\n",
    "# #             \"roomNbr\": roomNbr,\n",
    "# #             \"limit\": limit,\n",
    "# #             \"minPerWeek\": minPerWeek,\n",
    "# #             \"timePattern\": timePattern\n",
    "# #         }\n",
    "\n",
    "# #     def make_insert(self, d: Dict[str, Any]) -> str:\n",
    "# #         return f\"\"\"<offerings campus=\"{self.campus}\"\n",
    "# #            year=\"{self.year}\"\n",
    "# #            term=\"{self.term}\"\n",
    "# #            dateFormat=\"{self.date_format}\"\n",
    "# #            timeFormat=\"{self.time_format}\"\n",
    "# #            created=\"{self.created}\"\n",
    "# #            includeExams=\"{self.include_exams}\">\n",
    "\n",
    "# #   <offering offered=\"true\" action=\"insert\">\n",
    "# #     <course subject=\"{d['subject']}\" courseNbr=\"{d['courseNbr']}\" controlling=\"true\" title=\"{d['subject']}_{d['courseNbr']}\"/>\n",
    "# #     <config name=\"1\" limit=\"{d['limit']}\">\n",
    "# #       <subpart type=\"{d['classType']}\" suffix=\"\" minPerWeek=\"{d['minPerWeek']}\"/>\n",
    "# #       <class type=\"{d['classType']}\" suffix=\"L1\" limit=\"{d['limit']}\"\n",
    "# #              studentScheduling=\"true\" displayInScheduleBook=\"true\"\n",
    "# #              cancelled=\"false\" managingDept=\"{self.managing_dept}\">\n",
    "# #         <time days=\"{d['days']}\" startTime=\"{d['startTime']}\" endTime=\"{d['endTime']}\" timePattern=\"{d['timePattern']}\"/>\n",
    "# #         <room building=\"{d['buildingCode']}\" roomNbr=\"{d['roomNbr']}\"/>\n",
    "# #       </class>\n",
    "# #     </config>\n",
    "# #   </offering>\n",
    "# # </offerings>\"\"\"\n",
    "\n",
    "# #     def make_update(self, old: Dict[str, Any], new: Dict[str, Any]) -> str:\n",
    "# #         # Only update some fields: example limit, time, room\n",
    "# #         return f\"\"\"<offerings campus=\"{self.campus}\"\n",
    "# #            year=\"{self.year}\"\n",
    "# #            term=\"{self.term}\"\n",
    "# #            dateFormat=\"{self.date_format}\"\n",
    "# #            timeFormat=\"{self.time_format}\"\n",
    "# #            created=\"{self.created}\"\n",
    "# #            includeExams=\"{self.include_exams}\"\n",
    "# #            incremental=\"true\">\n",
    "\n",
    "# #   <offering offered=\"true\" action=\"update\">\n",
    "# #     <course subject=\"{old['subject']}\" courseNbr=\"{old['courseNbr']}\" controlling=\"true\" title=\"{old['subject']}_{old['courseNbr']}\"/>\n",
    "# #     <config name=\"1\" limit=\"{new['limit']}\">\n",
    "# #       <subpart type=\"{new['classType']}\" suffix=\"\" minPerWeek=\"{new['minPerWeek']}\"/>\n",
    "# #       <class type=\"{new['classType']}\" suffix=\"L1\" limit=\"{new['limit']}\"\n",
    "# #              studentScheduling=\"true\" displayInScheduleBook=\"true\"\n",
    "# #              cancelled=\"false\" managingDept=\"{self.managing_dept}\">\n",
    "# #         <time days=\"{new['days']}\" startTime=\"{new['startTime']}\" endTime=\"{new['endTime']}\" timePattern=\"{new['timePattern']}\"/>\n",
    "# #         <room building=\"{new['buildingCode']}\" roomNbr=\"{new['roomNbr']}\"/>\n",
    "# #       </class>\n",
    "# #     </config>\n",
    "# #   </offering>\n",
    "# # </offerings>\"\"\"\n",
    "\n",
    "# #     def generate_training_samples(self, count: int) -> List[Dict[str, str]]:\n",
    "# #         samples = []\n",
    "# #         for _ in range(count):\n",
    "# #             base = self._generate_base_details()\n",
    "# #             prompt_insert = f\"Add a new course offering: {base['subject']} {base['courseNbr']} as a {base['classType']} in {base['buildingName']} room {base['roomNbr']} on {base['days']} {base['startTime']}-{base['endTime']} with limit {base['limit']}.\"\n",
    "# #             xml_insert = self.make_insert(base)\n",
    "# #             samples.append({\"prompt\": prompt_insert, \"output\": xml_insert})\n",
    "\n",
    "# #             # Now make an update sample: change to a new random detail\n",
    "# #             new = self._generate_base_details()\n",
    "# #             prompt_update = f\"Update course {base['subject']} {base['courseNbr']} to room {new['buildingName']} {new['roomNbr']}, meeting {new['days']} at {new['startTime']}-{new['endTime']} and capacity {new['limit']}.\"\n",
    "# #             xml_update = self.make_update(base, new)\n",
    "# #             samples.append({\"prompt\": prompt_update, \"output\": xml_update})\n",
    "# #         return samples\n",
    "\n",
    "# #     def save(self, samples: List[Dict[str, str]], output_dir: str):\n",
    "# #         os.makedirs(output_dir, exist_ok=True)\n",
    "# #         train, temp = train_test_split(samples, test_size=0.3, random_state=42)\n",
    "# #         val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "# #         for fname, data in {\"train.jsonl\": train, \"validation.jsonl\": val, \"test.jsonl\": test}.items():\n",
    "# #             with open(os.path.join(output_dir, fname), \"w\", encoding=\"utf-8\") as f:\n",
    "# #                 for entry in data:\n",
    "# #                     json.dump(entry, f)\n",
    "# #                     f.write(\"\\n\")\n",
    "\n",
    "# # # Usage\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     gen = UniTimeDatasetGeneratorWithUpdate()\n",
    "# #     data = gen.generate_training_samples(1000)\n",
    "# #     gen.save(data, \"./unitime_update_dataset\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import json\n",
    "# import random\n",
    "# import os\n",
    "# from datetime import datetime\n",
    "# from typing import List, Dict, Any\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# class UniTimeDatasetGeneratorWithUpdate:\n",
    "#     def __init__(self):\n",
    "#         self.campus = \"woebegon\"\n",
    "#         self.year = \"2010\"\n",
    "#         self.term = \"Fal\"\n",
    "#         self.date_format = \"yyyy/M/d\"\n",
    "#         self.time_format = \"HHmm\"\n",
    "#         self.created = datetime.now().strftime(\"%a %b %d %H:%M:%S CEST %Y\")\n",
    "#         self.include_exams = \"none\"\n",
    "#         self.managing_dept = \"0100\"\n",
    "        \n",
    "#         # Possible data pools\n",
    "#         self.subjects = [\"CS\", \"MATH\", \"PHYS\", \"CHEM\", \"ENGL\"]\n",
    "#         self.course_numbers = [\"101\", \"201\", \"301\"]\n",
    "#         self.titles = {\n",
    "#             \"CS\": [\"Intro to Programming\", \"Data Structures\"],\n",
    "#             \"MATH\": [\"Calculus I\", \"Linear Algebra\"],\n",
    "#             \"PHYS\": [\"Physics I\", \"Physics II\"],\n",
    "#         }\n",
    "#         self.buildings = {\"Science Hall\": \"SCI\", \"Education Center\": \"EDU\", \"Engineering\": \"ENG\"}\n",
    "#         self.room_numbers = [\"101\", \"205\", \"301\", \"B08\"]\n",
    "#         self.day_patterns = [\"MWF\", \"TTh\"]\n",
    "#         self.time_slots = [(\"0830\", \"0920\", 50), (\"0930\", \"1020\", 50), (\"1330\", \"1420\", 50)]\n",
    "#         self.limits = [20, 25, 30, 40]\n",
    "#         self.class_types = [\"Lec\", \"Lab\"]\n",
    "\n",
    "#     def _calculate_min_per_week(self, days: str, duration: int) -> int:\n",
    "#         # Simple approach\n",
    "#         day_count = 0\n",
    "#         if \"M\" in days: day_count += 1\n",
    "#         if \"W\" in days: day_count += 1\n",
    "#         if \"F\" in days: day_count += 1\n",
    "#         if \"T\" in days and \"Th\" in days: day_count += 2\n",
    "#         elif \"T\" in days: day_count += 1\n",
    "#         return day_count * duration\n",
    "\n",
    "#     def _time_pattern(self, days: str, duration: int) -> str:\n",
    "#         # e.g. \"3 x 50\"\n",
    "#         day_count = len(days)  # naive\n",
    "#         return f\"{day_count} x {duration}\"\n",
    "\n",
    "#     def _generate_base_details(self) -> Dict[str, Any]:\n",
    "#         subject = random.choice(self.subjects)\n",
    "#         courseNbr = random.choice(self.course_numbers)\n",
    "#         title = random.choice(self.titles.get(subject, [\"Title\"]))\n",
    "#         classType = random.choice(self.class_types)\n",
    "#         (start, end, dur) = random.choice(self.time_slots)\n",
    "#         days = random.choice(self.day_patterns)\n",
    "#         buildingName = random.choice(list(self.buildings.keys()))\n",
    "#         buildingCode = self.buildings[buildingName]\n",
    "#         roomNbr = random.choice(self.room_numbers)\n",
    "#         limit = random.choice(self.limits)\n",
    "#         minPerWeek = self._calculate_min_per_week(days, dur)\n",
    "#         timePattern = self._time_pattern(days, dur)\n",
    "#         return {\n",
    "#             \"subject\": subject,\n",
    "#             \"courseNbr\": courseNbr,\n",
    "#             \"title_desc\": title,\n",
    "#             \"classType\": classType,\n",
    "#             \"startTime\": start,\n",
    "#             \"endTime\": end,\n",
    "#             \"days\": days,\n",
    "#             \"duration\": dur,\n",
    "#             \"buildingName\": buildingName,\n",
    "#             \"buildingCode\": buildingCode,\n",
    "#             \"roomNbr\": roomNbr,\n",
    "#             \"limit\": limit,\n",
    "#             \"minPerWeek\": minPerWeek,\n",
    "#             \"timePattern\": timePattern\n",
    "#         }\n",
    "\n",
    "#     def make_insert(self, d: Dict[str, Any]) -> str:\n",
    "#         return f\"\"\"<offerings campus=\"{self.campus}\"\n",
    "#            year=\"{self.year}\"\n",
    "#            term=\"{self.term}\"\n",
    "#            dateFormat=\"{self.date_format}\"\n",
    "#            timeFormat=\"{self.time_format}\"\n",
    "#            created=\"{self.created}\"\n",
    "#            includeExams=\"{self.include_exams}\">\n",
    "\n",
    "#   <offering offered=\"true\" action=\"insert\">\n",
    "#     <course subject=\"{d['subject']}\" courseNbr=\"{d['courseNbr']}\" controlling=\"true\" title=\"{d['subject']}_{d['courseNbr']}\"/>\n",
    "#     <config name=\"1\" limit=\"{d['limit']}\">\n",
    "#       <subpart type=\"{d['classType']}\" suffix=\"\" minPerWeek=\"{d['minPerWeek']}\"/>\n",
    "#       <class type=\"{d['classType']}\" suffix=\"L1\" limit=\"{d['limit']}\"\n",
    "#              studentScheduling=\"true\" displayInScheduleBook=\"true\"\n",
    "#              cancelled=\"false\" managingDept=\"{self.managing_dept}\">\n",
    "#         <time days=\"{d['days']}\" startTime=\"{d['startTime']}\" endTime=\"{d['endTime']}\" timePattern=\"{d['timePattern']}\"/>\n",
    "#         <room building=\"{d['buildingCode']}\" roomNbr=\"{d['roomNbr']}\"/>\n",
    "#       </class>\n",
    "#     </config>\n",
    "#   </offering>\n",
    "# </offerings>\"\"\"\n",
    "\n",
    "#     def make_update(self, old: Dict[str, Any], new: Dict[str, Any]) -> str:\n",
    "#         # Only update some fields: example limit, time, room\n",
    "#         return f\"\"\"<offerings campus=\"{self.campus}\"\n",
    "#            year=\"{self.year}\"\n",
    "#            term=\"{self.term}\"\n",
    "#            dateFormat=\"{self.date_format}\"\n",
    "#            timeFormat=\"{self.time_format}\"\n",
    "#            created=\"{self.created}\"\n",
    "#            includeExams=\"{self.include_exams}\"\n",
    "#            incremental=\"true\">\n",
    "\n",
    "#   <offering offered=\"true\" action=\"update\">\n",
    "#     <course subject=\"{old['subject']}\" courseNbr=\"{old['courseNbr']}\" controlling=\"true\" title=\"{old['subject']}_{old['courseNbr']}\"/>\n",
    "#     <config name=\"1\" limit=\"{new['limit']}\">\n",
    "#       <subpart type=\"{new['classType']}\" suffix=\"\" minPerWeek=\"{new['minPerWeek']}\"/>\n",
    "#       <class type=\"{new['classType']}\" suffix=\"L1\" limit=\"{new['limit']}\"\n",
    "#              studentScheduling=\"true\" displayInScheduleBook=\"true\"\n",
    "#              cancelled=\"false\" managingDept=\"{self.managing_dept}\">\n",
    "#         <time days=\"{new['days']}\" startTime=\"{new['startTime']}\" endTime=\"{new['endTime']}\" timePattern=\"{new['timePattern']}\"/>\n",
    "#         <room building=\"{new['buildingCode']}\" roomNbr=\"{new['roomNbr']}\"/>\n",
    "#       </class>\n",
    "#     </config>\n",
    "#   </offering>\n",
    "# </offerings>\"\"\"\n",
    "\n",
    "#     def generate_training_samples(self, count: int) -> List[Dict[str, str]]:\n",
    "#         samples = []\n",
    "#         for _ in range(count):\n",
    "#             base = self._generate_base_details()\n",
    "#             prompt_insert = f\"Add a new course offering: {base['subject']} {base['courseNbr']} as a {base['classType']} in {base['buildingName']} room {base['roomNbr']} on {base['days']} {base['startTime']}-{base['endTime']} with limit {base['limit']}.\"\n",
    "#             xml_insert = self.make_insert(base)\n",
    "#             samples.append({\"prompt\": prompt_insert, \"output\": xml_insert})\n",
    "\n",
    "#             # Now make an update sample: change to a new random detail\n",
    "#             new = self._generate_base_details()\n",
    "#             prompt_update = f\"Update course {base['subject']} {base['courseNbr']} to room {new['buildingName']} {new['roomNbr']}, meeting {new['days']} at {new['startTime']}-{new['endTime']} and capacity {new['limit']}.\"\n",
    "#             xml_update = self.make_update(base, new)\n",
    "#             samples.append({\"prompt\": prompt_update, \"output\": xml_update})\n",
    "#         return samples\n",
    "\n",
    "#     def save(self, samples: List[Dict[str, str]], output_dir: str):\n",
    "#         os.makedirs(output_dir, exist_ok=True)\n",
    "#         train, temp = train_test_split(samples, test_size=0.3, random_state=42)\n",
    "#         val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "#         for fname, data in {\"train.jsonl\": train, \"validation.jsonl\": val, \"test.jsonl\": test}.items():\n",
    "#             with open(os.path.join(output_dir, fname), \"w\", encoding=\"utf-8\") as f:\n",
    "#                 for entry in data:\n",
    "#                     json.dump(entry, f)\n",
    "#                     f.write(\"\\n\")\n",
    "\n",
    "# # Usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     gen = UniTimeDatasetGeneratorWithUpdate()\n",
    "#     data = gen.generate_training_samples(1000)\n",
    "#     gen.save(data, \"./unitime_update_dataset\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class UniTimeDatasetGeneratorWithUpdate:\n",
    "    def __init__(self):\n",
    "        self.campus = \"woebegon\"\n",
    "        self.year = \"2010\"\n",
    "        self.term = \"Fal\"\n",
    "        self.date_format = \"yyyy/M/d\"\n",
    "        self.time_format = \"HHmm\"\n",
    "        # Using a fixed format for training consistency, or dynamic if preferred\n",
    "        self.created = datetime.now().strftime(\"%a %b %d %H:%M:%S CEST %Y\")\n",
    "        self.include_exams = \"none\"\n",
    "        self.managing_dept = \"0100\"\n",
    "        \n",
    "        # Possible data pools\n",
    "        self.subjects = [\"CS\", \"MATH\", \"PHYS\", \"CHEM\", \"ENGL\", \"DLCS\", \"ALG\", \"DRL\"]\n",
    "        self.course_numbers = [\"101\", \"201\", \"301\", \"450\", \"106\"]\n",
    "        self.titles = {\n",
    "            \"CS\": [\"Intro to Programming\", \"Data Structures\", \"Algorithms\", \"AI Basics\"],\n",
    "            \"MATH\": [\"Calculus I\", \"Linear Algebra\", \"Statistics\", \"Discrete Math\"],\n",
    "            \"PHYS\": [\"Physics I\", \"Physics II\", \"Quantum Mechanics\"],\n",
    "            \"CHEM\": [\"Chemistry I\", \"Organic Chemistry\"],\n",
    "            \"ENGL\": [\"Composition\", \"Literature\", \"Creative Writing\"],\n",
    "            # \"DLCS\": [\"Deep Learning\", \"Advanced AI\", \"Neural Networks\"],\n",
    "            \"ALG\": [\"Algebra I\", \"Algebra II\"],\n",
    "            \"DRL\": [\"Deep Renforcement Learning\", \"Intro to RL\", \"RL Agents\"],\n",
    "            \"DLCS\": [\"Deep Learning CyberSecurity\", \"AI for Security\", \"Secure Deep Learning\", \"Deep Learning\"],\n",
    "            \"AOL\": [\"Approximation\", \"Approximation Algorithms\"],\n",
    "            \"CG\": [\"Computational Geometry\", \"Geometric Algorithms\", \"Advanced CG\"],\n",
    "            \"DBMS\": [\"Database Mangament System\", \"Intro to Databases\", \"SQL\", \"NoSQL Databases\"],\n",
    "            \"MVS\": [\"Multivariate Statistics\", \"Statistical Modeling\"],\n",
    "            \"ECN\": [\"Econometrics\", \"Intro to Econometrics\", \"Financial Econometrics\"],\n",
    "            \"MMD\": [\"Massive Data Mining\", \"Big Data Analytics\", \"Data Mining II\"]\n",
    "        }\n",
    "        self.buildings = {\"Science Hall\": \"SCI\", \"Education Center\": \"EDUC\", \"Engineering\": \"ENG\", \"Main Building\": \"MAIN\"}\n",
    "        self.room_numbers = [\"101\", \"205\", \"301\", \"B08\", \"106\", \"103\", \"404\"]\n",
    "        self.day_patterns = [\"MWF\", \"TTh\", \"MW\", \"T\", \"Th\"]\n",
    "        self.time_slots = [\n",
    "            (\"0830\", \"0920\", 50), \n",
    "            (\"0930\", \"1020\", 50), \n",
    "            (\"1030\", \"1120\", 50),\n",
    "            (\"1330\", \"1420\", 50),\n",
    "            (\"1430\", \"1520\", 50)\n",
    "        ]\n",
    "        self.limits = [20, 25, 30, 40, 50, 100]\n",
    "        self.class_types = [\"Lec\", \"Lab\", \"Rec\"]\n",
    "\n",
    "    def _calculate_min_per_week(self, days: str, duration: int) -> int:\n",
    "        day_count = 0\n",
    "        if \"M\" in days: day_count += 1\n",
    "        if \"W\" in days: day_count += 1\n",
    "        if \"F\" in days: day_count += 1\n",
    "        if \"T\" in days:\n",
    "            # Simple heuristic for T/Th patterns\n",
    "            if \"Th\" in days: \n",
    "                # \"TTh\" usually implies 2 days\n",
    "                # If \"T\" is present, we count it. \n",
    "                pass \n",
    "            else:\n",
    "                # Just \"T\"\n",
    "                pass\n",
    "        \n",
    "        # Robust counting\n",
    "        count = 0\n",
    "        if \"M\" in days: count += 1\n",
    "        if \"T\" in days: count += 1\n",
    "        if \"W\" in days: count += 1\n",
    "        if \"h\" in days: count += 0 # 'Th' logic handled by 'T' usually, but let's be safe\n",
    "        if \"F\" in days: count += 1\n",
    "        \n",
    "        # Fix for TTh specifically if needed, or just standard length * duration\n",
    "        # Assuming standard patterns:\n",
    "        if days == \"TTh\": count = 2\n",
    "        elif days == \"MWF\": count = 3\n",
    "        elif days == \"MW\": count = 2\n",
    "        elif days == \"T\": count = 1\n",
    "        elif days == \"Th\": count = 1\n",
    "        \n",
    "        return count * duration\n",
    "\n",
    "    def _time_pattern(self, days: str, duration: int) -> str:\n",
    "        # e.g. \"3 x 50\"\n",
    "        count = 0\n",
    "        if days == \"TTh\": count = 2\n",
    "        elif days == \"MWF\": count = 3\n",
    "        elif days == \"MW\": count = 2\n",
    "        elif days == \"T\": count = 1\n",
    "        elif days == \"Th\": count = 1\n",
    "        else: count = len(days) # fallback\n",
    "        return f\"{count} x {duration}\"\n",
    "\n",
    "    def _generate_base_details(self) -> Dict[str, Any]:\n",
    "        subject = random.choice(self.subjects)\n",
    "        courseNbr = random.choice(self.course_numbers)\n",
    "        # Get random title for subject, fallback to generic if key missing\n",
    "        title = random.choice(self.titles.get(subject, [f\"{subject} Basics\"]))\n",
    "        \n",
    "        classType = random.choice(self.class_types)\n",
    "        (start, end, dur) = random.choice(self.time_slots)\n",
    "        days = random.choice(self.day_patterns)\n",
    "        buildingName = random.choice(list(self.buildings.keys()))\n",
    "        buildingCode = self.buildings[buildingName]\n",
    "        roomNbr = random.choice(self.room_numbers)\n",
    "        limit = random.choice(self.limits)\n",
    "        \n",
    "        minPerWeek = self._calculate_min_per_week(days, dur)\n",
    "        timePattern = self._time_pattern(days, dur)\n",
    "        \n",
    "        return {\n",
    "            \"subject\": subject,\n",
    "            \"courseNbr\": courseNbr,\n",
    "            \"title_desc\": title,\n",
    "            \"classType\": classType,\n",
    "            \"startTime\": start,\n",
    "            \"endTime\": end,\n",
    "            \"days\": days,\n",
    "            \"duration\": dur,\n",
    "            \"buildingName\": buildingName,\n",
    "            \"buildingCode\": buildingCode,\n",
    "            \"roomNbr\": roomNbr,\n",
    "            \"limit\": limit,\n",
    "            \"minPerWeek\": minPerWeek,\n",
    "            \"timePattern\": timePattern\n",
    "        }\n",
    "\n",
    "    def make_insert(self, d: Dict[str, Any]) -> str:\n",
    "        # FIXED: Uses d['title_desc'] instead of subject_number\n",
    "        return f\"\"\"<offerings campus=\"{self.campus}\"\n",
    "           year=\"{self.year}\"\n",
    "           term=\"{self.term}\"\n",
    "           dateFormat=\"{self.date_format}\"\n",
    "           timeFormat=\"{self.time_format}\"\n",
    "           created=\"{self.created}\"\n",
    "           includeExams=\"{self.include_exams}\">\n",
    "\n",
    "  <offering offered=\"true\" action=\"insert\">\n",
    "    <course subject=\"{d['subject']}\" courseNbr=\"{d['courseNbr']}\" controlling=\"true\" title=\"{d['title_desc']}\"/>\n",
    "    <config name=\"1\" limit=\"{d['limit']}\">\n",
    "      <subpart type=\"{d['classType']}\" suffix=\"\" minPerWeek=\"{d['minPerWeek']}\"/>\n",
    "      <class type=\"{d['classType']}\" suffix=\"L1\" limit=\"{d['limit']}\"\n",
    "             studentScheduling=\"true\" displayInScheduleBook=\"true\"\n",
    "             cancelled=\"false\" managingDept=\"{self.managing_dept}\">\n",
    "        <time days=\"{d['days']}\" startTime=\"{d['startTime']}\" endTime=\"{d['endTime']}\" timePattern=\"{d['timePattern']}\"/>\n",
    "        <room building=\"{d['buildingCode']}\" roomNbr=\"{d['roomNbr']}\"/>\n",
    "      </class>\n",
    "    </config>\n",
    "  </offering>\n",
    "</offerings>\"\"\"\n",
    "\n",
    "    def make_update(self, old: Dict[str, Any], new: Dict[str, Any]) -> str:\n",
    "        # FIXED: Uses new['title_desc'] to reflect title updates in XML\n",
    "        return f\"\"\"<offerings campus=\"{self.campus}\"\n",
    "           year=\"{self.year}\"\n",
    "           term=\"{self.term}\"\n",
    "           dateFormat=\"{self.date_format}\"\n",
    "           timeFormat=\"{self.time_format}\"\n",
    "           created=\"{self.created}\"\n",
    "           includeExams=\"{self.include_exams}\"\n",
    "           incremental=\"true\">\n",
    "\n",
    "  <offering offered=\"true\" action=\"update\">\n",
    "    <course subject=\"{old['subject']}\" courseNbr=\"{old['courseNbr']}\" controlling=\"true\" title=\"{new['title_desc']}\"/>\n",
    "    <config name=\"1\" limit=\"{new['limit']}\">\n",
    "      <subpart type=\"{new['classType']}\" suffix=\"\" minPerWeek=\"{new['minPerWeek']}\"/>\n",
    "      <class type=\"{new['classType']}\" suffix=\"L1\" limit=\"{new['limit']}\"\n",
    "             studentScheduling=\"true\" displayInScheduleBook=\"true\"\n",
    "             cancelled=\"false\" managingDept=\"{self.managing_dept}\">\n",
    "        <time days=\"{new['days']}\" startTime=\"{new['startTime']}\" endTime=\"{new['endTime']}\" timePattern=\"{new['timePattern']}\"/>\n",
    "        <room building=\"{new['buildingCode']}\" roomNbr=\"{new['roomNbr']}\"/>\n",
    "      </class>\n",
    "    </config>\n",
    "  </offering>\n",
    "</offerings>\"\"\"\n",
    "\n",
    "    def generate_training_samples(self, count: int) -> List[Dict[str, str]]:\n",
    "        samples = []\n",
    "        for _ in range(count):\n",
    "            base = self._generate_base_details()\n",
    "            \n",
    "            # FIXED: Added \"titled '{base['title_desc']}'\" to the prompt\n",
    "            prompt_insert_Add= (\n",
    "                f\"Add a new course offering: {base['subject']} {base['courseNbr']} \"\n",
    "                f\"titled '{base['title_desc']}' as a {base['classType']} in {base['buildingName']} \"\n",
    "                f\"room {base['roomNbr']} on {base['days']} {base['startTime']}-{base['endTime']} \"\n",
    "                f\"with limit {base['limit']}.\"\n",
    "            )\n",
    "            xml_insert = self.make_insert(base)\n",
    "            samples.append({\"prompt\": prompt_insert_Add, \"output\": xml_insert})\n",
    "            \n",
    "            prompt_insert_insert= (\n",
    "                f\"Insert a new course offering: {base['subject']} {base['courseNbr']} \"\n",
    "                f\"titled '{base['title_desc']}' as a {base['classType']} in {base['buildingName']} \"\n",
    "                f\"room {base['roomNbr']} on {base['days']} {base['startTime']}-{base['endTime']} \"\n",
    "                f\"with limit {base['limit']}.\"\n",
    "            )\n",
    "            xml_insert = self.make_insert(base)\n",
    "            samples.append({\"prompt\": prompt_insert_insert, \"output\": xml_insert})\n",
    "\n",
    "            # Update Sample\n",
    "            new = self._generate_base_details()\n",
    "            # Keep identity (Subject + Number) same\n",
    "            new['subject'] = base['subject']\n",
    "            new['courseNbr'] = base['courseNbr']\n",
    "            \n",
    "            # FIXED: Added \"to title '{new['title_desc']}'\" to the update prompt\n",
    "            prompt_update = (\n",
    "                f\"Update course {base['subject']} {base['courseNbr']} \"\n",
    "                f\"to title '{new['title_desc']}', room {new['buildingName']} {new['roomNbr']}, \"\n",
    "                f\"meeting {new['days']} at {new['startTime']}-{new['endTime']} \"\n",
    "                f\"and capacity {new['limit']}.\"\n",
    "            )\n",
    "            xml_update = self.make_update(base, new)\n",
    "            samples.append({\"prompt\": prompt_update, \"output\": xml_update})\n",
    "            \n",
    "        return samples\n",
    "\n",
    "    def save(self, samples: List[Dict[str, str]], output_dir: str):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        train, temp = train_test_split(samples, test_size=0.3, random_state=42)\n",
    "        val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "        \n",
    "        for fname, data in {\"train.jsonl\": train, \"validation.jsonl\": val, \"test.jsonl\": test}.items():\n",
    "            with open(os.path.join(output_dir, fname), \"w\", encoding=\"utf-8\") as f:\n",
    "                for entry in data:\n",
    "                    json.dump(entry, f)\n",
    "                    f.write(\"\\n\")\n",
    "        print(f\"âœ… Generated {len(samples)} samples in '{output_dir}'\")\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    gen = UniTimeDatasetGeneratorWithUpdate()\n",
    "    # Generate a good amount of data for robust training\n",
    "    data = gen.generate_training_samples(2000)\n",
    "    gen.save(data, \"./unitime_update_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1fdea5",
   "metadata": {},
   "source": [
    "## TRAINING UPDATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdad8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fix_codet5p_q4_lora_final_fixed.py\n",
    "# import os, gc, json, torch\n",
    "# from transformers import (\n",
    "#     AutoTokenizer,\n",
    "#     AutoModelForSeq2SeqLM,\n",
    "#     Seq2SeqTrainer,             # <--- CHANGED: Use Seq2SeqTrainer\n",
    "#     Seq2SeqTrainingArguments,   # <--- CHANGED: Use Seq2SeqTrainingArguments\n",
    "#     DataCollatorForSeq2Seq,\n",
    "#     BitsAndBytesConfig,\n",
    "# )\n",
    "# from datasets import DatasetDict, Dataset\n",
    "# import numpy as np\n",
    "# import evaluate\n",
    "# from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 0ï¸âƒ£  CUDA + Memory Configuration\n",
    "# # ------------------------------------------------------------------\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 1ï¸âƒ£  Model + Tokenizer Setup\n",
    "# # ------------------------------------------------------------------\n",
    "# model_name = \"Salesforce/codet5p-220m\"\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.float16,\n",
    "#     bnb_4bit_use_double_quant=False,\n",
    "# )\n",
    "\n",
    "# print(\"ðŸš€ Loading quantized model (4-bit)...\")\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     quantization_config=bnb_config,\n",
    "#     device_map=\"auto\",\n",
    "#     trust_remote_code=True,\n",
    "# )\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#     model_name,\n",
    "#     trust_remote_code=True,\n",
    "#     add_bos_token=True,\n",
    "#     add_eos_token=True,\n",
    "#     use_fast=False,\n",
    "# )\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# print(\"âœ… Model & Tokenizer loaded.\")\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 2ï¸âƒ£  Prepare for LoRA\n",
    "# # ------------------------------------------------------------------\n",
    "# model = prepare_model_for_kbit_training(model)\n",
    "# model.gradient_checkpointing_enable()\n",
    "\n",
    "# lora_config = LoraConfig(\n",
    "#     r=16,\n",
    "#     lora_alpha=32,\n",
    "#     target_modules=[\"q\", \"k\", \"v\"],\n",
    "#     lora_dropout=0.05,\n",
    "#     bias=\"none\",\n",
    "#     task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "# )\n",
    "# peft_model = get_peft_model(model, lora_config)\n",
    "# peft_model.config.use_cache = False\n",
    "\n",
    "# def print_trainable_parameters(model):\n",
    "#     trainable_params, all_param = 0, 0\n",
    "#     for _, param in model.named_parameters():\n",
    "#         all_param += param.numel()\n",
    "#         if param.requires_grad:\n",
    "#             trainable_params += param.numel()\n",
    "#     print(f\"Trainable params: {trainable_params:,} / {all_param:,} ({100 * trainable_params / all_param:.2f}%)\")\n",
    "\n",
    "# print_trainable_parameters(peft_model)\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 3ï¸âƒ£  Dataset Loading\n",
    "# # ------------------------------------------------------------------\n",
    "# def flatten_jsonl(path):\n",
    "#     fixed = []\n",
    "#     with open(path) as f:\n",
    "#         for line in f:\n",
    "#             if not line.strip():\n",
    "#                 continue\n",
    "#             obj = json.loads(line)\n",
    "#             prompt = obj.get(\"prompt\", \"\")\n",
    "#             output = obj.get(\"output\", \"\")\n",
    "            \n",
    "#             if isinstance(prompt, list): prompt = \" \".join(map(str, prompt))\n",
    "#             if isinstance(output, list): output = \" \".join(map(str, output))\n",
    "\n",
    "#             fixed.append({\n",
    "#                 \"input_text\": prompt.strip(),\n",
    "#                 \"output_text\": output.strip(),\n",
    "#             })\n",
    "#     return fixed\n",
    "\n",
    "# data_files = {\n",
    "#     \"train\": \"/home/sysadm/Music/unitime_nlp/data_generator/unitime_update_dataset/train.jsonl\",\n",
    "#     \"validation\": \"/home/sysadm/Music/unitime_nlp/data_generator/unitime_update_dataset/validation.jsonl\",\n",
    "#     \"test\": \"/home/sysadm/Music/unitime_nlp/data_generator/unitime_update_dataset/test.jsonl\",\n",
    "# }\n",
    "\n",
    "# print(\"ðŸ“‚ Loading and flattening dataset...\")\n",
    "# splits = {k: flatten_jsonl(v) for k, v in data_files.items()}\n",
    "\n",
    "# dataset_dict = DatasetDict({\n",
    "#     \"train\": Dataset.from_list(splits[\"train\"]),\n",
    "#     \"validation\": Dataset.from_list(splits[\"validation\"]),\n",
    "#     \"test\": Dataset.from_list(splits[\"test\"]),\n",
    "# })\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 4ï¸âƒ£  Tokenization (CRITICAL FIX ADDED HERE)\n",
    "# # ------------------------------------------------------------------\n",
    "# MAX_INPUT_LENGTH = 512\n",
    "# MAX_TARGET_LENGTH = 1024 \n",
    "\n",
    "# def tokenize_function(batch):\n",
    "#     model_inputs = tokenizer(\n",
    "#         batch[\"input_text\"],\n",
    "#         max_length=MAX_INPUT_LENGTH,\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\",\n",
    "#     )\n",
    "#     labels = tokenizer(\n",
    "#         batch[\"output_text\"],\n",
    "#         max_length=MAX_TARGET_LENGTH,\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\",\n",
    "#     )\n",
    "#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "#     return model_inputs\n",
    "\n",
    "# # --- THIS WAS MISSING IN YOUR CODE ---\n",
    "# print(\"ðŸ§  Tokenizing...\")\n",
    "# tokenized_datasets = dataset_dict.map(\n",
    "#     tokenize_function,\n",
    "#     batched=True,\n",
    "#     remove_columns=[\"input_text\", \"output_text\"], # Remove text cols so Trainer doesn't get confused\n",
    "# )\n",
    "# print(\"âœ… Tokenization complete.\")\n",
    "# # -----------------------------------------\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 5ï¸âƒ£  Evaluation Metrics\n",
    "# # ------------------------------------------------------------------\n",
    "# cer_metric = evaluate.load(\"cer\")\n",
    "# bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "# def compute_metrics(eval_preds):\n",
    "#     preds, labels = eval_preds\n",
    "#     if isinstance(preds, tuple): pred_ids = preds[0]\n",
    "#     else: pred_ids = preds\n",
    "    \n",
    "#     decoded_preds = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "#     labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "#     cer = cer_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "#     return {\"cer\": cer}\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 6ï¸âƒ£  Training Arguments (Updated for Seq2Seq)\n",
    "# # ------------------------------------------------------------------\n",
    "# output_dir = \"./Offering-nlp-to-xml_update\" # Fixed typo\n",
    "# training_args = Seq2SeqTrainingArguments(  # <--- CHANGED CLASS\n",
    "#     output_dir=output_dir,\n",
    "#     num_train_epochs=7,\n",
    "#     per_device_train_batch_size=4,\n",
    "#     gradient_accumulation_steps=8,\n",
    "#     warmup_steps=1,\n",
    "#     weight_decay=0.01,\n",
    "#     learning_rate=2e-4,\n",
    "#     optim=\"paged_adamw_8bit\",\n",
    "#     logging_dir=\"./logs\",\n",
    "#     logging_steps=30,\n",
    "    \n",
    "#     # Eval settings\n",
    "#     eval_strategy=\"no\",\n",
    "#     do_eval=False,\n",
    "#     save_strategy=\"steps\",\n",
    "#     save_steps=100,\n",
    "    \n",
    "#     predict_with_generate=True, # <--- Enabled for Seq2Seq\n",
    "#     generation_max_length=1024, # <--- Ensure XML isn't cut off\n",
    "    \n",
    "#     gradient_checkpointing=True,\n",
    "#     fp16=True,\n",
    "#     report_to=\"none\",\n",
    "#     remove_unused_columns=False,\n",
    "# )\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 7ï¸âƒ£  Trainer (Updated for Seq2Seq)\n",
    "# # ------------------------------------------------------------------\n",
    "# data_collator = DataCollatorForSeq2Seq(tokenizer, model=peft_model, padding=\"longest\")\n",
    "\n",
    "# trainer = Seq2SeqTrainer( # <--- CHANGED CLASS\n",
    "#     model=peft_model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_datasets[\"train\"],\n",
    "#     eval_dataset=tokenized_datasets[\"validation\"],\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 8ï¸âƒ£  Training\n",
    "# # ------------------------------------------------------------------\n",
    "# def pre_train_cleanup():\n",
    "#     gc.collect()\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "# pre_train_cleanup()\n",
    "\n",
    "# print(\"\\nðŸ”¥ Starting fine-tuning (memory-safe QLoRA)...\")\n",
    "# trainer.train()\n",
    "# print(\"ðŸŽ‰ Fine-tuning complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f8017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, json, torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainer, \n",
    "    Seq2SeqTrainingArguments, \n",
    "    DataCollatorForSeq2Seq,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from datasets import DatasetDict, Dataset\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 0ï¸âƒ£  CUDA + Memory Configuration\n",
    "# ------------------------------------------------------------------\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1ï¸âƒ£  Model + Tokenizer Setup\n",
    "# ------------------------------------------------------------------\n",
    "model_name = \"Salesforce/codet5p-220m\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")\n",
    "\n",
    "print(\"ðŸš€ Loading quantized model (4-bit)...\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# --- FIX 1: Use Fast Tokenizer to prevent \"NoneType\" decoding errors ---\n",
    "print(\"ðŸ”§ Loading Tokenizer (Fast)...\")\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        use_fast=True, # Changed to True for stability\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Failed to load fast tokenizer ({e}), falling back to slow...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        use_fast=False,\n",
    "    )\n",
    "\n",
    "print(f\"âœ… Model & Tokenizer loaded. Pad Token ID: {tokenizer.pad_token_id}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2ï¸âƒ£  Prepare for LoRA\n",
    "# ------------------------------------------------------------------\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32, \n",
    "    lora_alpha=64,\n",
    "    target_modules=[\"q\", \"k\", \"v\", \"o\"], \n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "peft_model.config.use_cache = False\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    trainable_params, all_param = 0, 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(f\"Trainable params: {trainable_params:,} / {all_param:,} ({100 * trainable_params / all_param:.2f}%)\")\n",
    "\n",
    "print_trainable_parameters(peft_model)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3ï¸âƒ£  Dataset Loading\n",
    "# ------------------------------------------------------------------\n",
    "def flatten_jsonl(path):\n",
    "    fixed = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"âš ï¸ Warning: {path} not found.\")\n",
    "        return []\n",
    "        \n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if not line.strip(): continue\n",
    "            obj = json.loads(line)\n",
    "            prompt = obj.get(\"prompt\", \"\")\n",
    "            output = obj.get(\"output\", \"\")\n",
    "            \n",
    "            if isinstance(prompt, list): prompt = \" \".join(map(str, prompt))\n",
    "            if isinstance(output, list): output = \" \".join(map(str, output))\n",
    "\n",
    "            fixed.append({\n",
    "                \"input_text\": prompt.strip(),\n",
    "                \"output_text\": output.strip(),\n",
    "            })\n",
    "    return fixed\n",
    "\n",
    "base_data_path = \"./unitime_update_dataset\"\n",
    "data_files = {\n",
    "    \"train\": f\"{base_data_path}/train.jsonl\",\n",
    "    \"validation\": f\"{base_data_path}/validation.jsonl\",\n",
    "    \"test\": f\"{base_data_path}/test.jsonl\",\n",
    "}\n",
    "\n",
    "print(\"ðŸ“‚ Loading and flattening dataset...\")\n",
    "splits = {k: flatten_jsonl(v) for k, v in data_files.items()}\n",
    "\n",
    "if not splits[\"train\"]:\n",
    "    raise ValueError(\"âŒ No training data found! Did you run the generator script?\")\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": Dataset.from_list(splits[\"train\"]),\n",
    "    \"validation\": Dataset.from_list(splits[\"validation\"]),\n",
    "    \"test\": Dataset.from_list(splits[\"test\"]),\n",
    "})\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4ï¸âƒ£  Tokenization (WITH -100 FIX)\n",
    "# ------------------------------------------------------------------\n",
    "MAX_INPUT_LENGTH = 512\n",
    "MAX_TARGET_LENGTH = 1024 \n",
    "\n",
    "def tokenize_function(batch):\n",
    "    model_inputs = tokenizer(\n",
    "        batch[\"input_text\"],\n",
    "        max_length=MAX_INPUT_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        batch[\"output_text\"],\n",
    "        max_length=MAX_TARGET_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    \n",
    "    # --- ðŸš¨ CRITICAL FIX: Replace Padding with -100 ðŸš¨ ---\n",
    "    labels_with_ignore_index = []\n",
    "    for label_ids in labels[\"input_ids\"]:\n",
    "        label_ids = [label if label != tokenizer.pad_token_id else -100 for label in label_ids]\n",
    "        labels_with_ignore_index.append(label_ids)\n",
    "        \n",
    "    model_inputs[\"labels\"] = labels_with_ignore_index\n",
    "    return model_inputs\n",
    "\n",
    "print(\"ðŸ§  Tokenizing...\")\n",
    "tokenized_datasets = dataset_dict.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"input_text\", \"output_text\"], \n",
    ")\n",
    "print(\"âœ… Tokenization complete.\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5ï¸âƒ£  Evaluation Metrics\n",
    "# ------------------------------------------------------------------\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple): pred_ids = preds[0]\n",
    "    else: pred_ids = preds\n",
    "    \n",
    "    # Replace -100 in labels with pad_token_id\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    \n",
    "    # --- FIX 2: Sanitize IDs to prevent Tokenizer Crash ---\n",
    "    # Sometimes QLoRA output produces OOB IDs initially, or preds contain -100\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    \n",
    "    # Clip predictions to valid range [0, vocab_size-1]\n",
    "    # This prevents the \"NoneType found\" error in slow tokenizer if it happens\n",
    "    pred_ids = np.clip(pred_ids, 0, vocab_size - 1)\n",
    "    labels = np.clip(labels, 0, vocab_size - 1)\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    cer = cer_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {\"cer\": cer}\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6ï¸âƒ£  Training Arguments\n",
    "# ------------------------------------------------------------------\n",
    "output_dir = \"./Offering-nlp-to-xml_update_v2\" \n",
    "training_args = Seq2SeqTrainingArguments( \n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=50,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=3e-4,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    \n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    \n",
    "    predict_with_generate=True, \n",
    "    generation_max_length=1024, \n",
    "    \n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 7ï¸âƒ£  Trainer\n",
    "# ------------------------------------------------------------------\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer, \n",
    "    model=peft_model, \n",
    "    label_pad_token_id=-100, \n",
    "    padding=\"longest\"\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer( \n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 8ï¸âƒ£  Training\n",
    "# ------------------------------------------------------------------\n",
    "def pre_train_cleanup():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "pre_train_cleanup()\n",
    "\n",
    "print(\"\\nðŸ”¥ Starting fine-tuning (memory-safe QLoRA)...\")\n",
    "trainer.train()\n",
    "print(\"ðŸŽ‰ Fine-tuning complete!\")\n",
    "\n",
    "# Save the final adapter\n",
    "trainer.save_model(os.path.join(output_dir, \"final_adapter\"))\n",
    "print(f\"ðŸ’¾ Adapter saved to {output_dir}/final_adapter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7c77b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "import gc\n",
    "\n",
    "# --- 1. Define Model Names ---\n",
    "base_model_name = \"Salesforce/codet5p-220m\"\n",
    "# adapter_path = \"/home/sysadm/Music/unitime_nlp/test/Offereing-nlp-to-xml/checkpoint-462\"\n",
    "adapter_path=\"/home/sysadm/Music/unitime_nlp/data_generator/Offereing-nlp-to-xml_update/checkpoint-308\"\n",
    "# --- 2. Load 4-bit Config ---\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "# --- 3. Load Base Model (Quantized) ---\n",
    "print(f\"Loading base model: {base_model_name}\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",  # Automatically uses your GPU\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# --- 4. Load Tokenizer ---\n",
    "# (Must match the settings you trained with)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_name,\n",
    "    trust_remote_code=True,\n",
    "    add_bos_token=True,\n",
    "    add_eos_token=True,\n",
    "    use_fast=False,\n",
    ")\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# --- 5. Load the PEFT Adapter ---\n",
    "print(f\"Loading adapter from: {adapter_path}\")\n",
    "# This line merges your saved adapter onto the base model\n",
    "model = PeftModel.from_pretrained(model, adapter_path)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(\"âœ… Model is ready for inference!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e3a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- 6. Define Input ---\n",
    "# context = \"COURSE OFFERING REQUEST\"\n",
    "# prompt_text = \"Update a new class: CG 101(computational Geometry). Place it in EDUC Room 103 on Monday, Wednesday, Friday 03:30 PM to 05:00 PM. It's a Lec with a limit of 15 students.\"\n",
    "\n",
    "# # Format input just like training\n",
    "# input_text = f\"{context.strip()} {prompt_text.strip()}\".strip()\n",
    "# inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# # --- 7. Generate ---\n",
    "# print(\"...Generating XML...\")\n",
    "# with torch.no_grad():\n",
    "#     outputs = model.generate(\n",
    "#         **inputs,\n",
    "#         max_new_tokens=512,   # Your MAX_TARGET_LENGTH\n",
    "#         num_beams=4,          # Use beam search for better results\n",
    "#         early_stopping=False,\n",
    "#         pad_token_id=tokenizer.pad_token_id\n",
    "#     )\n",
    "\n",
    "# xml_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# print(\"\\n--- Generated XML ---\")\n",
    "# print(xml_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f422e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "from bs4 import BeautifulSoup\n",
    "import gc\n",
    "\n",
    "# --- 1. Define Model Names ---\n",
    "base_model_name = \"Salesforce/codet5p-220m\"\n",
    "adapter_path = \"/home/sysadm/Music/unitime_nlp/data_generator/Offering-nlp-to-xml_update_v2/checkpoint-875\"\n",
    "\n",
    "# --- 2. Load 4-bit Config ---\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "# --- 3. Load Base Model ---\n",
    "print(f\"Loading base model: {base_model_name}\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# --- 4. Load Tokenizer ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_name,\n",
    "    trust_remote_code=True,\n",
    "    use_fast=False,\n",
    ")\n",
    "\n",
    "# --- 5. Load Adapter ---\n",
    "print(f\"Loading adapter from: {adapter_path}\")\n",
    "model = PeftModel.from_pretrained(model, adapter_path)\n",
    "model.eval()\n",
    "\n",
    "# --- 6. Define Input ---\n",
    "prompt_text = \"Update course dlcs 101 to room Engineering 101, meeting MWF at 0830-0920 and capacity 30.\"\n",
    "print(f\"Input Prompt: {prompt_text}\")\n",
    "\n",
    "inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# --- 7. Generate ---\n",
    "print(\"...Generating XML...\")\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=512,\n",
    "        num_beams=4,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "# --- 8. Decode ---\n",
    "raw_xml_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# --- 9. PROCESSING & FIXING (The Magic Step) ---\n",
    "print(\"\\n--- Processing Output ---\")\n",
    "soup = BeautifulSoup(raw_xml_output, 'xml')\n",
    "offering_tag = soup.find('offering')\n",
    "\n",
    "if offering_tag:\n",
    "    # --- LOGIC FIX: Correction Mechanism ---\n",
    "    # The model works great for structure, but might mess up specific names.\n",
    "    # We look at the generated XML to see which Course Number it picked (e.g., \"101\").\n",
    "    course_tag = offering_tag.find('course')\n",
    "    \n",
    "    if course_tag and course_tag.has_attr('courseNbr'):\n",
    "        xml_course_nbr = course_tag['courseNbr']\n",
    "        \n",
    "        # We define a Regex to find the Subject associated with that Number in the USER INPUT\n",
    "        # Pattern: Look for word characters immediately before the course number\n",
    "        # Example: matches \"dlcs\" in \"dlcs 101\" or \"CS\" in \"CS 101\"\n",
    "        pattern = re.compile(rf\"([a-zA-Z]+)\\s*{xml_course_nbr}\", re.IGNORECASE)\n",
    "        match = pattern.search(prompt_text)\n",
    "        \n",
    "        if match:\n",
    "            real_subject = match.group(1).upper() # Extract \"DLCS\" and uppercase it\n",
    "            generated_subject = course_tag.get('subject', '')\n",
    "            \n",
    "            # If they don't match, we trust the USER INPUT over the model\n",
    "            if real_subject != generated_subject:\n",
    "                print(f\"âš ï¸ Correction applied: Changed subject '{generated_subject}' to '{real_subject}'\")\n",
    "                course_tag['subject'] = real_subject\n",
    "                # Also update the title to match: DLCS_101\n",
    "                course_tag['title'] = f\"{real_subject}_{xml_course_nbr}\"\n",
    "\n",
    "    final_xml = str(offering_tag)\n",
    "    print(\"âœ… Final XML:\")\n",
    "    print(final_xml)\n",
    "else:\n",
    "    print(\"âŒ Could not find <offering> tag.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
