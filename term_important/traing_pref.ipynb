{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "127f95bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Loading quantized model (4-bit)...\n",
      "Tokenizer Pad Token: <pad>\n",
      "Tokenizer EOS Token: </s>\n",
      "‚úÖ Model & Tokenizer loaded.\n"
     ]
    }
   ],
   "source": [
    "import os, gc, json, torch\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import DatasetDict, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainer,             # <--- Add\n",
    "    Seq2SeqTrainingArguments,   # <--- Add\n",
    "    DataCollatorForSeq2Seq,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType, PeftModel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 0Ô∏è‚É£  CUDA + Memory Configuration\n",
    "# ------------------------------------------------------------------\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1Ô∏è‚É£  Model + Tokenizer Setup\n",
    "# ------------------------------------------------------------------\n",
    "model_name = \"Salesforce/codet5p-220m\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")\n",
    "\n",
    "print(\"üöÄ Loading quantized model (4-bit)...\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    add_bos_token=True,\n",
    "    add_eos_token=True,\n",
    "    use_fast=True,\n",
    ")\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# Explicitly check if pad_token is missing before assigning\n",
    "# if tokenizer.pad_token is None:\n",
    "#     tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Ensure pad_token_id is an integer, not None\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    print(f\"‚ö†Ô∏è Pad Token was None, set to EOS ID: {tokenizer.pad_token_id}\")\n",
    "    \n",
    "print(f\"Tokenizer Pad Token: {tokenizer.pad_token}\")\n",
    "print(f\"Tokenizer EOS Token: {tokenizer.eos_token}\")\n",
    "print(\"‚úÖ Model & Tokenizer loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa97b5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 2,654,208 / 154,757,376 (1.72%)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 2Ô∏è‚É£  Prepare for LoRA (k-bit training)\n",
    "# ------------------------------------------------------------------\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"k\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    ")\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "peft_model.config.use_cache = False\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    trainable_params, all_param = 0, 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(f\"Trainable params: {trainable_params:,} / {all_param:,} \"\n",
    "          f\"({100 * trainable_params / all_param:.2f}%)\")\n",
    "\n",
    "print_trainable_parameters(peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f4a3bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading and flattening dataset...\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_text', 'output_text'],\n",
      "        num_rows: 1750\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_text', 'output_text'],\n",
      "        num_rows: 375\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_text', 'output_text'],\n",
      "        num_rows: 375\n",
      "    })\n",
      "})\n",
      "üß† Tokenizing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c9297bf30342c6a083b4ffdc5b7ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9677a5ce441400c9902fafd888196b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50dae6d260404be8b4860952868d757a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tokenization complete.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 3Ô∏è‚É£  Dataset Loading (FIXED for new dataset format)\n",
    "# ------------------------------------------------------------------\n",
    "def flatten_jsonl(path):\n",
    "    fixed = []\n",
    "    # Using utf-8 encoding is safer\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            obj = json.loads(line)\n",
    "\n",
    "            # 1. Get the fields\n",
    "            # We NO LONGER look for \"context\" as the new data doesn't have it.\n",
    "            prompt = obj.get(\"prompt\", \"\")\n",
    "            output = obj.get(\"output\", \"\")\n",
    "\n",
    "            # 2. Flatten lists if necessary (safety check)\n",
    "            if isinstance(prompt, list): prompt = \" \".join(map(str, prompt))\n",
    "            if isinstance(output, list): output = \" \".join(map(str, output))\n",
    "\n",
    "            # 3. Create combined input text\n",
    "            # Format: \"Prompt: <instruction>\\nXML:\"\n",
    "            input_text = f\"Prompt: {prompt.strip()}\\nXML:\".strip()\n",
    "\n",
    "            fixed.append({\n",
    "                \"input_text\": input_text,\n",
    "                \"output_text\": str(output),\n",
    "            })\n",
    "    return fixed\n",
    "\n",
    "# Update these paths to where your 'generate_unitime_data.py' saved the files\n",
    "# Assuming relative path from where you run the script:\n",
    "data_files = {\n",
    "    \"train\": \"/home/sysadm/Music/unitime/unitime_nlp/data/Preferences_dataset/train.jsonl\",\n",
    "    \"validation\": \"/home/sysadm/Music/unitime/unitime_nlp/data/Preferences_dataset/validation.jsonl\",\n",
    "    \"test\": \"/home/sysadm/Music/unitime/unitime_nlp/data/Preferences_dataset/test.jsonl\",\n",
    "}\n",
    "\n",
    "print(\"üìÇ Loading and flattening dataset...\")\n",
    "# Verify files exist\n",
    "for k, v in data_files.items():\n",
    "    if not os.path.exists(v):\n",
    "        print(f\"‚ö†Ô∏è Warning: File not found: {v}\")\n",
    "\n",
    "splits = {k: flatten_jsonl(v) for k, v in data_files.items()}\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": Dataset.from_list(splits[\"train\"]),\n",
    "    \"validation\": Dataset.from_list(splits[\"validation\"]),\n",
    "    \"test\": Dataset.from_list(splits[\"test\"]),\n",
    "})\n",
    "print(dataset_dict)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4Ô∏è‚É£  Tokenization\n",
    "# ------------------------------------------------------------------\n",
    "MAX_INPUT_LENGTH = 512\n",
    "MAX_TARGET_LENGTH = 512\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    model_inputs = tokenizer(\n",
    "        batch[\"input_text\"],\n",
    "        max_length=MAX_INPUT_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        batch[\"output_text\"],\n",
    "        max_length=MAX_TARGET_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "print(\"üß† Tokenizing...\")\n",
    "tokenized_datasets = dataset_dict.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"input_text\", \"output_text\"],\n",
    ")\n",
    "print(\"‚úÖ Tokenization complete.\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5Ô∏è‚É£  Evaluation Metrics\n",
    "# ------------------------------------------------------------------\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "# def compute_metrics(eval_preds):\n",
    "#     preds, labels = eval_preds\n",
    "#     if isinstance(preds, tuple) or (hasattr(preds, \"ndim\") and preds.ndim == 3):\n",
    "#         pred_ids = np.argmax(preds, axis=-1)\n",
    "#     else:\n",
    "#         pred_ids = preds\n",
    "#     labels = np.where(labels == -100, tokenizer.pad_token_id, labels)\n",
    "#     decoded_preds = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "#     exact_match = np.mean([p.strip() == l.strip() for p, l in zip(decoded_preds, decoded_labels)])\n",
    "#     cer = cer_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "#     decoded_labels_for_bleu = [[label] for label in decoded_labels]\n",
    "#     bleu = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels_for_bleu)\n",
    "    \n",
    "#     return {\n",
    "#         \"exact_match\": round(float(exact_match), 4),\n",
    "#         \"cer\": round(float(cer), 4),\n",
    "#         \"bleu\": round(float(bleu[\"score\"]), 4),\n",
    "#     }\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    \n",
    "    # 1. Handle tuple predictions (some models return (logits, past_key_values))\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "        \n",
    "    # 2. Convert to numpy if not already (safety check)\n",
    "    if not isinstance(preds, np.ndarray):\n",
    "        preds = np.array(preds)\n",
    "    if not isinstance(labels, np.ndarray):\n",
    "        labels = np.array(labels)\n",
    "\n",
    "    # 3. Replace -100 in LABELS with pad_token_id (Critical for Loss masking)\n",
    "    #    -100 is used to ignore tokens during loss calculation, but crashes the decoder.\n",
    "    decoded_labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    \n",
    "    # 4. Replace -100 in PREDICTIONS (Critical safety net)\n",
    "    #    Sometimes generation produces -100 or garbage if not configured right.\n",
    "    decoded_preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n",
    "\n",
    "    # 5. Decode\n",
    "    #    skip_special_tokens=True removes <pad>, <s>, </s> automatically\n",
    "    decoded_preds = tokenizer.batch_decode(decoded_preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(decoded_labels, skip_special_tokens=True)\n",
    "\n",
    "    # 6. Clean up text (trim whitespace)\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [label.strip() for label in decoded_labels]\n",
    "\n",
    "    # 7. Metrics Calculation\n",
    "    exact_match = np.mean([p == l for p, l in zip(decoded_preds, decoded_labels)])\n",
    "    \n",
    "    # Handle edge case: Empty strings can crash CER\n",
    "    # We replace empty strings with a single space if necessary, or just let metric handle it\n",
    "    cer = cer_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # BLEU expects references as list of lists\n",
    "    decoded_labels_for_bleu = [[label] for label in decoded_labels]\n",
    "    bleu = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels_for_bleu)\n",
    "    \n",
    "    return {\n",
    "        \"exact_match\": round(float(exact_match), 4),\n",
    "        \"cer\": round(float(cer), 4),\n",
    "        \"bleu\": round(float(bleu[\"score\"]), 4),\n",
    "    }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4629281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1277901/693901939.py:111: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(            # <--- Changed Class\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî• Starting fine-tuning (memory-safe QLoRA)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='151' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [151/495 23:05 < 53:18, 0.11 it/s, Epoch 2.73/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact Match</th>\n",
       "      <th>Cer</th>\n",
       "      <th>Bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.244100</td>\n",
       "      <td>4.135072</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>93.841900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.228400</td>\n",
       "      <td>4.133172</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>96.323000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='94' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/94 01:04 < 05:35, 0.23 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # ------------------------------------------------------------------\n",
    "# # 6Ô∏è‚É£  Training Arguments (memory-safe)\n",
    "# # ------------------------------------------------------------------\n",
    "# output_dir = \"./Preference-nlp-to-xml_1st\"\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=output_dir,\n",
    "#     num_train_epochs=7,\n",
    "#     per_device_train_batch_size=4,\n",
    "#     gradient_accumulation_steps=8,\n",
    "#     warmup_steps=1,\n",
    "#     weight_decay=0.01,\n",
    "#     learning_rate=2e-4,\n",
    "#     optim=\"paged_adamw_8bit\",\n",
    "#     logging_dir=\"./logs\",\n",
    "#     logging_steps=30,\n",
    "    \n",
    "#     # Validation settings\n",
    "#     eval_strategy=\"yes\",\n",
    "#     do_eval=False,\n",
    "    \n",
    "#     # Checkpointing\n",
    "#     save_strategy=\"steps\",\n",
    "#     save_steps=100,\n",
    "    \n",
    "#     gradient_checkpointing=True,\n",
    "#     load_best_model_at_end=False,\n",
    "#     fp16=True,\n",
    "#     report_to=\"none\",\n",
    "#     remove_unused_columns=False,\n",
    "# )\n",
    "\n",
    "# print(\"‚úÖ TrainingArguments configured.\")\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 7Ô∏è‚É£  Trainer\n",
    "# # ------------------------------------------------------------------\n",
    "# data_collator = DataCollatorForSeq2Seq(tokenizer, model=peft_model, padding=\"longest\")\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=peft_model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_datasets[\"train\"],\n",
    "#     eval_dataset=tokenized_datasets[\"validation\"],\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 8Ô∏è‚É£  Training (with cleanup)\n",
    "# # ------------------------------------------------------------------\n",
    "# def pre_train_cleanup():\n",
    "#     gc.collect()\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "# pre_train_cleanup()\n",
    "\n",
    "# print(\"\\nüî• Starting fine-tuning (memory-safe QLoRA)...\")\n",
    "# trainer.train()\n",
    "# print(\"üéâ Fine-tuning complete!\")\n",
    "\n",
    "# # Save the final adapter\n",
    "# final_adapter_path = os.path.join(output_dir, \"final_adapter\")\n",
    "# trainer.save_model(final_adapter_path)\n",
    "# print(f\"üíæ Adapter saved to: {final_adapter_path}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6Ô∏è‚É£  Training Arguments (Updated for Evaluation)\n",
    "# ------------------------------------------------------------------\n",
    "output_dir = \"./Preference-nlp-to-xml_2nd\"\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(  # <--- Changed class\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=9,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,    # <--- Add eval batch size\n",
    "    gradient_accumulation_steps=8,\n",
    "    warmup_steps=1,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-4,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=30,\n",
    "\n",
    "    # --- Evaluation Settings ---\n",
    "    eval_strategy=\"steps\",     # Evaluate every X steps\n",
    "    eval_steps=50,                  # Match this with save_steps usually\n",
    "    do_eval=True,                    # <--- MUST be True\n",
    "    predict_with_generate=True,      # <--- CRITICAL: Generates text for BLEU/CER\n",
    "    generation_max_length=512,       # Limit generation length during eval\n",
    "    \n",
    "    # Checkpointing & Saving\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    load_best_model_at_end=True,     # Optional: Load best model based on metric\n",
    "    metric_for_best_model=\"cer\",     # Optional: Monitor CER\n",
    "    greater_is_better=False,         # Optional: Lower CER is better\n",
    "\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 7Ô∏è‚É£  Trainer (Updated to Seq2SeqTrainer)\n",
    "# ------------------------------------------------------------------\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=peft_model, padding=\"longest\")\n",
    "\n",
    "trainer = Seq2SeqTrainer(            # <--- Changed Class\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 8Ô∏è‚É£  Training (with cleanup)\n",
    "# # ------------------------------------------------------------------\n",
    "def pre_train_cleanup():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "pre_train_cleanup()\n",
    "\n",
    "print(\"\\nüî• Starting fine-tuning (memory-safe QLoRA)...\")\n",
    "trainer.train()\n",
    "print(\"üéâ Fine-tuning complete!\")\n",
    "\n",
    "# Save the final adapter\n",
    "final_adapter_path = os.path.join(output_dir, \"final_adapter\")\n",
    "trainer.save_model(final_adapter_path)\n",
    "print(f\"üíæ Adapter saved to: {final_adapter_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ccf1567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Generating Learning Curves...\n",
      "‚úÖ Learning curve saved to: ./Preference-nlp-to-xml_2nd/learning_curve.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  # <--- Re-import ensures 'plt' is the module, not a function\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# üìä Plotting Learning Curves\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\nüìà Generating Learning Curves...\")\n",
    "\n",
    "# 1. Extract logs from trainer history\n",
    "# 'trainer' must be defined from your previous training cell\n",
    "history = trainer.state.log_history\n",
    "\n",
    "train_steps = []\n",
    "train_loss = []\n",
    "eval_steps = []\n",
    "eval_loss = []\n",
    "\n",
    "for log in history:\n",
    "    # Extract training loss\n",
    "    if \"loss\" in log and \"step\" in log:\n",
    "        train_steps.append(log[\"step\"])\n",
    "        train_loss.append(log[\"loss\"])\n",
    "    \n",
    "    # Extract validation loss (only present if do_eval=True)\n",
    "    if \"eval_loss\" in log and \"step\" in log:\n",
    "        eval_steps.append(log[\"step\"])\n",
    "        eval_loss.append(log[\"eval_loss\"])\n",
    "\n",
    "# 2. Create the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot training loss\n",
    "plt.plot(train_steps, train_loss, label=\"Training Loss\", alpha=0.6, color=\"blue\")\n",
    "\n",
    "# Plot validation loss (if available)\n",
    "if eval_loss:\n",
    "    plt.plot(eval_steps, eval_loss, label=\"Validation Loss\", alpha=1.0, color=\"red\", linewidth=2, marker='o')\n",
    "\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# 3. Save the plot to a file\n",
    "plot_path = os.path.join(output_dir, \"learning_curve.png\")\n",
    "plt.savefig(plot_path)\n",
    "print(f\"‚úÖ Learning curve saved to: {plot_path}\")\n",
    "\n",
    "# Display the plot in the notebook\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... (after trainer.save_model) ...\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 9Ô∏è‚É£  Final Evaluation on Test Set\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\nüìä Running evaluation on the Test set...\")\n",
    "\n",
    "# Run evaluation\n",
    "metrics = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n",
    "\n",
    "print(\"\\n--- Test Set Metrics ---\")\n",
    "print(f\"Refined BLEU:  {metrics['eval_bleu']}\")\n",
    "print(f\"Refined CER:   {metrics['eval_cer']}\")\n",
    "print(f\"Exact Match:   {metrics['eval_exact_match']}\")\n",
    "print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d5aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Running manual evaluation (memory-safe)...\n",
      "...Evaluation complete. Computing metrics.\n",
      "üìä Evaluation metrics: {'exact_match': 0.0, 'cer': 0.1723, 'bleu': 79.1321}\n"
     ]
    }
   ],
   "source": [
    "# # ------------------------------------------------------------------\n",
    "# # 9Ô∏è‚É£ Manual Evaluation (Validation Set)\n",
    "# # ------------------------------------------------------------------\n",
    "# print(\"\\nüìä Running manual evaluation (memory-safe)...\")\n",
    "\n",
    "# # Set model to evaluation mode\n",
    "# peft_model.eval()\n",
    "\n",
    "# eval_dataset = tokenized_datasets[\"validation\"]\n",
    "# eval_loader = DataLoader(eval_dataset, batch_size=1, collate_fn=data_collator)\n",
    "\n",
    "# all_preds, all_labels = [], []\n",
    "\n",
    "# for batch in eval_loader:\n",
    "#     input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "#     attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "#     labels = batch[\"labels\"].numpy()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         generated_ids = peft_model.generate(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask,\n",
    "#             max_new_tokens=512,\n",
    "#             num_beams=1,\n",
    "#             pad_token_id=tokenizer.pad_token_id\n",
    "#         )\n",
    "    \n",
    "#     preds = generated_ids.cpu().numpy()\n",
    "    \n",
    "#     # --- Padding Fix ---\n",
    "#     label_length = labels.shape[1]\n",
    "#     padded_preds = np.full((preds.shape[0], label_length), tokenizer.pad_token_id)\n",
    "#     copy_length = min(preds.shape[1], label_length)\n",
    "#     padded_preds[:, :copy_length] = preds[:, :copy_length]\n",
    "    \n",
    "#     all_preds.extend(padded_preds)\n",
    "#     all_labels.extend(labels)\n",
    "\n",
    "#     # Cleanup\n",
    "#     del input_ids, attention_mask, labels, batch, generated_ids, preds, padded_preds\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "# print(\"...Evaluation complete. Computing metrics.\")\n",
    "# metrics = compute_metrics((np.array(all_preds), np.array(all_labels)))\n",
    "# print(\"üìä Evaluation metrics:\", metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d7e88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Reloading model for inference check...\n",
      "Loading adapter from: ./Preference-nlp-to-xml_1st/final_adapter\n",
      "Input to model:\n",
      "Prompt: For instructor JOE DOE, make the time slot T 1630-1830 required.\n",
      "XML:\n",
      "...Generating XML...\n",
      "\n",
      "--- Generated XML ---\n",
      "<preferences term=\"Fal\" year=\"2010\" campus=\"woebegon\" dateFormat=\"yyyy/M/d\" timeFormat=\"HHmm\" created=\"Sun Dec 07 01:16:06 IST 2025\">\n",
      "<instructor externalId=\"100\" firstName=\"JOE\" lastName=\"DOE\" department=\"0101\">\n",
      "<timePref level=\"R\">\n",
      "<pref level=\"R\" day=\"T\" start=\"1630\" stop=\"1830\"/>\n",
      "</timePref>\n",
      "</instructor>\n",
      "</preferences>\n"
     ]
    }
   ],
   "source": [
    "# # ------------------------------------------------------------------\n",
    "# # üîü Inference Check (Reloading Base + Adapter)\n",
    "# # ------------------------------------------------------------------\n",
    "# print(\"\\nüîÑ Reloading model for inference check...\")\n",
    "\n",
    "# # Clean up memory first\n",
    "# del peft_model, model, trainer\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # Load Base Model Again\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     quantization_config=bnb_config,\n",
    "#     device_map=\"auto\",\n",
    "#     trust_remote_code=True,\n",
    "# )\n",
    "\n",
    "# # Load the Adapter we just saved\n",
    "# print(f\"Loading adapter from: {final_adapter_path}\")\n",
    "# model = PeftModel.from_pretrained(model, final_adapter_path)\n",
    "# model.eval()\n",
    "\n",
    "# # Define Input - MATCHING TRAINING FORMAT EXACTLY\n",
    "# prompt_text = \"For instructor JOE DOE, make the time slot T 1630-1830 required.\"\n",
    "# input_text = f\"Prompt: {prompt_text.strip()}\\nXML:\"\n",
    "\n",
    "# print(f\"Input to model:\\n{input_text}\")\n",
    "# inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# print(\"...Generating XML...\")\n",
    "# with torch.no_grad():\n",
    "#     outputs = model.generate(\n",
    "#         **inputs,\n",
    "#         max_new_tokens=512,\n",
    "#         num_beams=4,\n",
    "#         early_stopping=True,\n",
    "#         pad_token_id=tokenizer.pad_token_id,\n",
    "#         eos_token_id=tokenizer.eos_token_id\n",
    "#     )\n",
    "\n",
    "# xml_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# print(\"\\n--- Generated XML ---\")\n",
    "# print(xml_output)\n",
    "# ------------------------------------------------------------------\n",
    "# üîü Inference Check (Reloading Base + Adapter)\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\nüîÑ Reloading model for inference check...\")\n",
    "\n",
    "# # Clean up memory first\n",
    "# del peft_model, model, trainer\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# Load Base Model Again\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Load the Adapter we just saved\n",
    "print(f\"Loading adapter from: {final_adapter_path}\")\n",
    "model = PeftModel.from_pretrained(model, final_adapter_path)\n",
    "model.eval()\n",
    "\n",
    "# Define Input\n",
    "prompt_text = \"For instructor JOE DOE, make the time slot T 1630-1830 required.\"\n",
    "input_text = f\"Prompt: {prompt_text.strip()}\\nXML:\"\n",
    "\n",
    "print(f\"Input to model:\\n{input_text}\")\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "print(\"...Generating XML...\")\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        num_beams=4,\n",
    "        early_stopping=True,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# Decode\n",
    "xml_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# --- THE FIX IS HERE ---\n",
    "# Manually remove the artifact if it persists\n",
    "xml_output = xml_output.replace(\"<pad>\", \"\").strip()\n",
    "\n",
    "print(\"\\n--- Generated XML ---\")\n",
    "print(xml_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769e2d26",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3426b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, gc, json, torch\n",
    "# import numpy as np\n",
    "# import evaluate\n",
    "# from datasets import DatasetDict, Dataset\n",
    "# from transformers import (\n",
    "#     AutoTokenizer,\n",
    "#     AutoModelForSeq2SeqLM,\n",
    "#     Trainer,\n",
    "#     TrainingArguments,\n",
    "#     DataCollatorForSeq2Seq,\n",
    "#     BitsAndBytesConfig,\n",
    "# )\n",
    "# from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType, PeftModel\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 0Ô∏è‚É£  CUDA + Memory Configuration\n",
    "# # ------------------------------------------------------------------\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 1Ô∏è‚É£  Model + Tokenizer Setup\n",
    "# # ------------------------------------------------------------------\n",
    "# model_name = \"Salesforce/codet5p-220m\"\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.float16,\n",
    "#     bnb_4bit_use_double_quant=False,\n",
    "# )\n",
    "\n",
    "# print(\"üöÄ Loading quantized model (4-bit)...\")\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     quantization_config=bnb_config,\n",
    "#     device_map=\"auto\",\n",
    "#     trust_remote_code=True,\n",
    "# )\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#     model_name,\n",
    "#     trust_remote_code=True,\n",
    "#     add_bos_token=True,\n",
    "#     add_eos_token=True,\n",
    "#     use_fast=False,\n",
    "# )\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# print(\"‚úÖ Model & Tokenizer loaded.\")\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 2Ô∏è‚É£  Prepare for LoRA (k-bit training)\n",
    "# # ------------------------------------------------------------------\n",
    "# model = prepare_model_for_kbit_training(model)\n",
    "# model.gradient_checkpointing_enable()\n",
    "\n",
    "# lora_config = LoraConfig(\n",
    "#     r=16,\n",
    "#     lora_alpha=32,\n",
    "#     target_modules=[\"q\", \"k\", \"v\"],\n",
    "#     lora_dropout=0.05,\n",
    "#     bias=\"none\",\n",
    "#     task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "# )\n",
    "# peft_model = get_peft_model(model, lora_config)\n",
    "# peft_model.config.use_cache = False\n",
    "\n",
    "# def print_trainable_parameters(model):\n",
    "#     trainable_params, all_param = 0, 0\n",
    "#     for _, param in model.named_parameters():\n",
    "#         all_param += param.numel()\n",
    "#         if param.requires_grad:\n",
    "#             trainable_params += param.numel()\n",
    "#     print(f\"Trainable params: {trainable_params:,} / {all_param:,} \"\n",
    "#           f\"({100 * trainable_params / all_param:.2f}%)\")\n",
    "\n",
    "# print_trainable_parameters(peft_model)\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 3Ô∏è‚É£  Dataset Loading (FIXED for new dataset format)\n",
    "# # ------------------------------------------------------------------\n",
    "# def flatten_jsonl(path):\n",
    "#     fixed = []\n",
    "#     # Using utf-8 encoding is safer\n",
    "#     with open(path, 'r', encoding='utf-8') as f:\n",
    "#         for line in f:\n",
    "#             if not line.strip():\n",
    "#                 continue\n",
    "#             obj = json.loads(line)\n",
    "\n",
    "#             # 1. Get the fields\n",
    "#             # We NO LONGER look for \"context\" as the new data doesn't have it.\n",
    "#             prompt = obj.get(\"prompt\", \"\")\n",
    "#             output = obj.get(\"output\", \"\")\n",
    "\n",
    "#             # 2. Flatten lists if necessary (safety check)\n",
    "#             if isinstance(prompt, list): prompt = \" \".join(map(str, prompt))\n",
    "#             if isinstance(output, list): output = \" \".join(map(str, output))\n",
    "\n",
    "#             # 3. Create combined input text\n",
    "#             # Format: \"Prompt: <instruction>\\nXML:\"\n",
    "#             input_text = f\"Prompt: {prompt.strip()}\\nXML:\".strip()\n",
    "\n",
    "#             fixed.append({\n",
    "#                 \"input_text\": input_text,\n",
    "#                 \"output_text\": str(output),\n",
    "#             })\n",
    "#     return fixed\n",
    "\n",
    "# # Update these paths to where your 'generate_unitime_data.py' saved the files\n",
    "# # Assuming relative path from where you run the script:\n",
    "# data_files = {\n",
    "#     \"train\": \"/home/sysadm/Music/unitime/unitime_nlp/data/Preferences_dataset/train.jsonl\",\n",
    "#     \"validation\": \"/home/sysadm/Music/unitime/unitime_nlp/data/Preferences_dataset/validation.jsonl\",\n",
    "#     \"test\": \"/home/sysadm/Music/unitime/unitime_nlp/data/Preferences_dataset/test.jsonl\",\n",
    "# }\n",
    "\n",
    "# print(\"üìÇ Loading and flattening dataset...\")\n",
    "# # Verify files exist\n",
    "# for k, v in data_files.items():\n",
    "#     if not os.path.exists(v):\n",
    "#         print(f\"‚ö†Ô∏è Warning: File not found: {v}\")\n",
    "\n",
    "# splits = {k: flatten_jsonl(v) for k, v in data_files.items()}\n",
    "\n",
    "# dataset_dict = DatasetDict({\n",
    "#     \"train\": Dataset.from_list(splits[\"train\"]),\n",
    "#     \"validation\": Dataset.from_list(splits[\"validation\"]),\n",
    "#     \"test\": Dataset.from_list(splits[\"test\"]),\n",
    "# })\n",
    "# print(dataset_dict)\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 4Ô∏è‚É£  Tokenization\n",
    "# # ------------------------------------------------------------------\n",
    "# MAX_INPUT_LENGTH = 512\n",
    "# MAX_TARGET_LENGTH = 512\n",
    "\n",
    "# def tokenize_function(batch):\n",
    "#     model_inputs = tokenizer(\n",
    "#         batch[\"input_text\"],\n",
    "#         max_length=MAX_INPUT_LENGTH,\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\",\n",
    "#     )\n",
    "#     labels = tokenizer(\n",
    "#         batch[\"output_text\"],\n",
    "#         max_length=MAX_TARGET_LENGTH,\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\",\n",
    "#     )\n",
    "#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "#     return model_inputs\n",
    "\n",
    "# print(\"üß† Tokenizing...\")\n",
    "# tokenized_datasets = dataset_dict.map(\n",
    "#     tokenize_function,\n",
    "#     batched=True,\n",
    "#     remove_columns=[\"input_text\", \"output_text\"],\n",
    "# )\n",
    "# print(\"‚úÖ Tokenization complete.\")\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 5Ô∏è‚É£  Evaluation Metrics\n",
    "# # ------------------------------------------------------------------\n",
    "# cer_metric = evaluate.load(\"cer\")\n",
    "# bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "# def compute_metrics(eval_preds):\n",
    "#     preds, labels = eval_preds\n",
    "#     if isinstance(preds, tuple) or (hasattr(preds, \"ndim\") and preds.ndim == 3):\n",
    "#         pred_ids = np.argmax(preds, axis=-1)\n",
    "#     else:\n",
    "#         pred_ids = preds\n",
    "#     labels = np.where(labels == -100, tokenizer.pad_token_id, labels)\n",
    "#     decoded_preds = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "#     exact_match = np.mean([p.strip() == l.strip() for p, l in zip(decoded_preds, decoded_labels)])\n",
    "#     cer = cer_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "#     decoded_labels_for_bleu = [[label] for label in decoded_labels]\n",
    "#     bleu = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels_for_bleu)\n",
    "    \n",
    "#     return {\n",
    "#         \"exact_match\": round(float(exact_match), 4),\n",
    "#         \"cer\": round(float(cer), 4),\n",
    "#         \"bleu\": round(float(bleu[\"score\"]), 4),\n",
    "#     }\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 6Ô∏è‚É£  Training Arguments (memory-safe)\n",
    "# # ------------------------------------------------------------------\n",
    "# output_dir = \"./Preference-nlp-to-xml_1st\"\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=output_dir,\n",
    "#     num_train_epochs=7,\n",
    "#     per_device_train_batch_size=4,\n",
    "#     gradient_accumulation_steps=8,\n",
    "#     warmup_steps=1,\n",
    "#     weight_decay=0.01,\n",
    "#     learning_rate=2e-4,\n",
    "#     optim=\"paged_adamw_8bit\",\n",
    "#     logging_dir=\"./logs\",\n",
    "#     logging_steps=30,\n",
    "    \n",
    "#     # Validation settings\n",
    "#     eval_strategy=\"no\",\n",
    "#     do_eval=False,\n",
    "    \n",
    "#     # Checkpointing\n",
    "#     save_strategy=\"steps\",\n",
    "#     save_steps=100,\n",
    "    \n",
    "#     gradient_checkpointing=True,\n",
    "#     load_best_model_at_end=False,\n",
    "#     fp16=True,\n",
    "#     report_to=\"none\",\n",
    "#     remove_unused_columns=False,\n",
    "# )\n",
    "\n",
    "# print(\"‚úÖ TrainingArguments configured.\")\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 7Ô∏è‚É£  Trainer\n",
    "# # ------------------------------------------------------------------\n",
    "# data_collator = DataCollatorForSeq2Seq(tokenizer, model=peft_model, padding=\"longest\")\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=peft_model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_datasets[\"train\"],\n",
    "#     eval_dataset=tokenized_datasets[\"validation\"],\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 8Ô∏è‚É£  Training (with cleanup)\n",
    "# # ------------------------------------------------------------------\n",
    "# def pre_train_cleanup():\n",
    "#     gc.collect()\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "# pre_train_cleanup()\n",
    "\n",
    "# print(\"\\nüî• Starting fine-tuning (memory-safe QLoRA)...\")\n",
    "# trainer.train()\n",
    "# print(\"üéâ Fine-tuning complete!\")\n",
    "\n",
    "# # Save the final adapter\n",
    "# final_adapter_path = os.path.join(output_dir, \"final_adapter\")\n",
    "# trainer.save_model(final_adapter_path)\n",
    "# print(f\"üíæ Adapter saved to: {final_adapter_path}\")\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 9Ô∏è‚É£ Manual Evaluation (Validation Set)\n",
    "# # ------------------------------------------------------------------\n",
    "# print(\"\\nüìä Running manual evaluation (memory-safe)...\")\n",
    "\n",
    "# # Set model to evaluation mode\n",
    "# peft_model.eval()\n",
    "\n",
    "# eval_dataset = tokenized_datasets[\"validation\"]\n",
    "# eval_loader = DataLoader(eval_dataset, batch_size=1, collate_fn=data_collator)\n",
    "\n",
    "# all_preds, all_labels = [], []\n",
    "\n",
    "# for batch in eval_loader:\n",
    "#     input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "#     attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "#     labels = batch[\"labels\"].numpy()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         generated_ids = peft_model.generate(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask,\n",
    "#             max_new_tokens=512,\n",
    "#             num_beams=1,\n",
    "#             pad_token_id=tokenizer.pad_token_id\n",
    "#         )\n",
    "    \n",
    "#     preds = generated_ids.cpu().numpy()\n",
    "    \n",
    "#     # --- Padding Fix ---\n",
    "#     label_length = labels.shape[1]\n",
    "#     padded_preds = np.full((preds.shape[0], label_length), tokenizer.pad_token_id)\n",
    "#     copy_length = min(preds.shape[1], label_length)\n",
    "#     padded_preds[:, :copy_length] = preds[:, :copy_length]\n",
    "    \n",
    "#     all_preds.extend(padded_preds)\n",
    "#     all_labels.extend(labels)\n",
    "\n",
    "#     # Cleanup\n",
    "#     del input_ids, attention_mask, labels, batch, generated_ids, preds, padded_preds\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "# print(\"...Evaluation complete. Computing metrics.\")\n",
    "# metrics = compute_metrics((np.array(all_preds), np.array(all_labels)))\n",
    "# print(\"üìä Evaluation metrics:\", metrics)\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # üîü Inference Check (Reloading Base + Adapter)\n",
    "# # ------------------------------------------------------------------\n",
    "# print(\"\\nüîÑ Reloading model for inference check...\")\n",
    "\n",
    "# # Clean up memory first\n",
    "# del peft_model, model, trainer\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # Load Base Model Again\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     quantization_config=bnb_config,\n",
    "#     device_map=\"auto\",\n",
    "#     trust_remote_code=True,\n",
    "# )\n",
    "\n",
    "# # Load the Adapter we just saved\n",
    "# print(f\"Loading adapter from: {final_adapter_path}\")\n",
    "# model = PeftModel.from_pretrained(model, final_adapter_path)\n",
    "# model.eval()\n",
    "\n",
    "# # Define Input - MATCHING TRAINING FORMAT EXACTLY\n",
    "# prompt_text = \"For instructor JOE DOE, make the time slot T 1630-1830 required.\"\n",
    "# input_text = f\"Prompt: {prompt_text.strip()}\\nXML:\"\n",
    "\n",
    "# print(f\"Input to model:\\n{input_text}\")\n",
    "# inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# print(\"...Generating XML...\")\n",
    "# with torch.no_grad():\n",
    "#     outputs = model.generate(\n",
    "#         **inputs,\n",
    "#         max_new_tokens=512,\n",
    "#         num_beams=4,\n",
    "#         early_stopping=True,\n",
    "#         pad_token_id=tokenizer.pad_token_id,\n",
    "#         eos_token_id=tokenizer.eos_token_id\n",
    "#     )\n",
    "\n",
    "# xml_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# print(\"\\n--- Generated XML ---\")\n",
    "# print(xml_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_agentic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
